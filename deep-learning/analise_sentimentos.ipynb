{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758d8ef6-4b5a-46c4-9e25-0f1a2520b88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISE: TAMANHO DAS SENTENÇAS\n",
      "============================================================\n",
      "\n",
      "Estatísticas de tamanho:\n",
      "\n",
      "Caracteres:\n",
      "  Média: 1243\n",
      "  Mediana: 866\n",
      "  Máximo: 13363\n",
      "\n",
      "Palavras:\n",
      "  Média: 198\n",
      "  Mediana: 140\n",
      "  Máximo: 2112\n",
      "\n",
      "Tokens estimados:\n",
      "  Média: 257\n",
      "  Mediana: 181\n",
      "  Máximo: 2745\n",
      "\n",
      "============================================================\n",
      "DISTRIBUIÇÃO POR FAIXA DE TOKENS\n",
      "============================================================\n",
      "\n",
      "Bert 512                  (    0-  512 tokens): 682 ( 90.2%)\n",
      "513 - 1024                (  513- 1024 tokens):  48 (  6.3%)\n",
      "1025 - 4096               ( 1025- 4096 tokens):  25 (  3.3%)\n",
      "> 4096                    ( 4097-16384 tokens):   0 (  0.0%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "verificar_tamanho_sentencas.py\n",
    "Verifica distribuição de tamanho das sentenças\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANÁLISE: TAMANHO DAS SENTENÇAS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "df = pd.read_csv('processos_tjac_com_genero.csv')\n",
    "df_sentencas = df[df['procedente'].notna()].copy()\n",
    "\n",
    "# Calcular tamanhos\n",
    "df_sentencas['num_caracteres'] = df_sentencas['desc'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "df_sentencas['num_palavras'] = df_sentencas['desc'].apply(lambda x: len(str(x).split()) if pd.notna(x) else 0)\n",
    "\n",
    "# Estimar tokens (aproximadamente 1.3 palavras = 1 token em português)\n",
    "df_sentencas['tokens_estimados'] = (df_sentencas['num_palavras'] * 1.3).astype(int)\n",
    "\n",
    "print(\"Estatísticas de tamanho:\\n\")\n",
    "print(f\"Caracteres:\")\n",
    "print(f\"  Média: {df_sentencas['num_caracteres'].mean():.0f}\")\n",
    "print(f\"  Mediana: {df_sentencas['num_caracteres'].median():.0f}\")\n",
    "print(f\"  Máximo: {df_sentencas['num_caracteres'].max():.0f}\")\n",
    "\n",
    "print(f\"\\nPalavras:\")\n",
    "print(f\"  Média: {df_sentencas['num_palavras'].mean():.0f}\")\n",
    "print(f\"  Mediana: {df_sentencas['num_palavras'].median():.0f}\")\n",
    "print(f\"  Máximo: {df_sentencas['num_palavras'].max():.0f}\")\n",
    "\n",
    "print(f\"\\nTokens estimados:\")\n",
    "print(f\"  Média: {df_sentencas['tokens_estimados'].mean():.0f}\")\n",
    "print(f\"  Mediana: {df_sentencas['tokens_estimados'].median():.0f}\")\n",
    "print(f\"  Máximo: {df_sentencas['tokens_estimados'].max():.0f}\")\n",
    "\n",
    "# Distribuição\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUIÇÃO POR FAIXA DE TOKENS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "faixas = [\n",
    "    (0, 512, 'Bert 512'),\n",
    "    (513, 1024, '513 - 1024'),\n",
    "    (1025, 4096, '1025 - 4096'),\n",
    "    (4097, 16384, '> 4096')\n",
    "]\n",
    "\n",
    "for min_tok, max_tok, modelo in faixas:\n",
    "    count = ((df_sentencas['tokens_estimados'] > min_tok) & (df_sentencas['tokens_estimados'] <= max_tok)).sum()\n",
    "    pct = count / len(df_sentencas) * 100\n",
    "    print(f\"{modelo:25} ({min_tok:5}-{max_tok:5} tokens): {count:3} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9654dbee-f47e-47d2-92f8-1b21ac3fd154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GERAÇÃO DE ARQUIVOS FINAIS - ANÁLISE NLP\n",
      "================================================================================\n",
      "\n",
      "1. Carregando dataset...\n",
      "\n",
      "Dataset carregado: 1200 processos\n",
      "Com sentença identificada: 756 processos\n",
      "\n",
      "2. Carregando modelo BERT-PT...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT-PT carregado!\n",
      "\n",
      "3. Processando 756 sentenças com NLP...\n",
      "\n",
      "   Processadas: 50/756\n",
      "   Processadas: 100/756\n",
      "   Processadas: 150/756\n",
      "   Processadas: 200/756\n",
      "   Processadas: 250/756\n",
      "   Processadas: 300/756\n",
      "   Processadas: 350/756\n",
      "   Processadas: 400/756\n",
      "   Processadas: 450/756\n",
      "   Processadas: 500/756\n",
      "   Processadas: 550/756\n",
      "   Processadas: 600/756\n",
      "   Processadas: 650/756\n",
      "   Processadas: 700/756\n",
      "   Processadas: 750/756\n",
      "\n",
      "756 sentenças processadas!\n",
      "\n",
      "4. Criando arquivo de legenda...\n",
      "\n",
      "Legenda salva: LEGENDA_NLP.txt\n",
      "\n",
      "5. Salvando arquivos finais...\n",
      "\n",
      "Salvo: processos_tjac_completo_nlp.csv\n",
      "Salvo: processos_tjac_completo_nlp_excel.csv (sep=;)\n",
      "Salvo: processos_tjac_completo_nlp.xlsx\n",
      "\n",
      "================================================================================\n",
      "ARQUIVOS GERADOS COM SUCESSO!\n",
      "================================================================================\n",
      "\n",
      "Total de processos: 756\n",
      "Total de colunas: 20\n",
      "\n",
      "Arquivos gerados:\n",
      "  1. processos_tjac_completo_nlp.csv (padrão)\n",
      "  2. processos_tjac_completo_nlp_excel.csv (Excel BR)\n",
      "  3. processos_tjac_completo_nlp.xlsx (Excel nativo)\n",
      "  4. LEGENDA_NLP.txt (documentação)\n",
      "\n",
      "Novas colunas NLP:\n",
      "  • sentimento_sentenca (positivo/neutro/negativo)\n",
      "  • sentimento_score (0-1)\n",
      "  • complexidade_sentenca (alta/média/baixa)\n",
      "  • complexidade_score (0-100)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gerar_csv_xlsx_nlp_final.py\n",
    "Gera CSV e XLSX com análise NLP completa\n",
    "Sem estatísticas (será feito em arquivo separado)\n",
    "\"\"\"\n",
    "\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import textstat\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GERAÇÃO DE ARQUIVOS FINAIS - ANÁLISE NLP\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Configurar textstat para português\n",
    "textstat.set_lang('pt')\n",
    "\n",
    "# ==================== CARREGAR DATASET ====================\n",
    "print(\"1. Carregando dataset...\\n\")\n",
    "\n",
    "df = pd.read_csv('processos_tjac_com_genero.csv')\n",
    "df_analise = df[df['procedente'].notna()].copy()\n",
    "\n",
    "print(f\"Dataset carregado: {len(df)} processos\")\n",
    "print(f\"Com sentença identificada: {len(df_analise)} processos\\n\")\n",
    "\n",
    "# ==================== CARREGAR MODELO BERT-PT ====================\n",
    "print(\"2. Carregando modelo BERT-PT...\\n\")\n",
    "\n",
    "analisador_sentimento = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"lipaoMai/bert-sentiment-model-portuguese\",\n",
    "    framework='pt', #força o uso do torch ao invés do keras\n",
    "    device=-1, ##para rodar na GPU altere para 0 (zero). 1070TI não teve compatibilidade com a versão do torch, por isso ficou na cpu\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "print(\"BERT-PT carregado!\\n\")\n",
    "\n",
    "# ==================== MAPEAMENTOS PARA PORTUGUÊS ====================\n",
    "\n",
    "MAP_SENTIMENTO = {\n",
    "    'POSITIVE': 'positivo',\n",
    "    'NEGATIVE': 'negativo',\n",
    "    'NEUTRAL': 'neutro'\n",
    "}\n",
    "\n",
    "def classificar_flesch_ajustado(score):\n",
    "    \"\"\"Classifica complexidade adaptado para textos jurídicos\"\"\"\n",
    "    score = max(0, score)\n",
    "    \n",
    "    if score >= 56:\n",
    "        return 'baixa'\n",
    "    elif score >= 36:\n",
    "        return 'média'\n",
    "    else:\n",
    "        return 'alta'\n",
    "\n",
    "def analisar_sentenca(texto):\n",
    "    \"\"\"Analisa sentimento e complexidade\"\"\"\n",
    "    if pd.isna(texto) or not texto:\n",
    "        return None, 0.0, None, 0.0\n",
    "    \n",
    "    texto_str = str(texto)\n",
    "    \n",
    "    # SENTIMENTO\n",
    "    try:\n",
    "        sent_result = analisador_sentimento(texto_str)[0]\n",
    "        sentimento_en = sent_result['label']\n",
    "        sentimento_pt = MAP_SENTIMENTO.get(sentimento_en, sentimento_en.lower())\n",
    "        sent_score = sent_result['score']\n",
    "    except:\n",
    "        sentimento_pt = None\n",
    "        sent_score = 0.0\n",
    "    \n",
    "    # COMPLEXIDADE\n",
    "    try:\n",
    "        flesch_raw = textstat.flesch_reading_ease(texto_str)\n",
    "        flesch_score = max(0, flesch_raw)\n",
    "        complexidade = classificar_flesch_ajustado(flesch_score)\n",
    "    except:\n",
    "        flesch_score = 0.0\n",
    "        complexidade = None\n",
    "    \n",
    "    return sentimento_pt, sent_score, complexidade, flesch_score\n",
    "\n",
    "# ==================== PROCESSAR TODAS AS SENTENÇAS ====================\n",
    "print(\"3. Processando 756 sentenças com NLP...\\n\")\n",
    "sentimentos = []\n",
    "sentimentos_scores = []\n",
    "complexidades = []\n",
    "complexidades_scores = []\n",
    "\n",
    "for i, desc in enumerate(df_analise['desc'], 1):\n",
    "    sentimento, sent_score, complexidade, flesch_score = analisar_sentenca(desc)\n",
    "    \n",
    "    sentimentos.append(sentimento)\n",
    "    sentimentos_scores.append(sent_score)\n",
    "    complexidades.append(complexidade)\n",
    "    complexidades_scores.append(flesch_score)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(f\"   Processadas: {i}/{len(df_analise)}\")\n",
    "\n",
    "# Adicionar colunas\n",
    "df_analise['sentimento_sentenca'] = sentimentos\n",
    "df_analise['sentimento_score'] = sentimentos_scores\n",
    "df_analise['complexidade_sentenca'] = complexidades\n",
    "df_analise['complexidade_score'] = complexidades_scores\n",
    "\n",
    "print(f\"\\n{len(df_analise)} sentenças processadas!\\n\")\n",
    "\n",
    "# ==================== CRIAR LEGENDA ====================\n",
    "print(\"4. Criando arquivo de legenda...\\n\")\n",
    "\n",
    "legenda = \"\"\"\n",
    "LEGENDA - ANÁLISE NLP DAS SENTENÇAS\n",
    "====================================\n",
    "\n",
    "COLUNAS ADICIONADAS:\n",
    "-------------------\n",
    "\n",
    "1. sentimento_sentenca\n",
    "   Classificação do sentimento/tom do texto da sentença\n",
    "   Valores possíveis:\n",
    "   - positivo: Tom favorável/ameno\n",
    "   - neutro: Tom técnico/formal (maioria dos casos jurídicos)\n",
    "   - negativo: Tom severo/desfavorável\n",
    "   \n",
    "   Método: Modelo BERT-PT fine-tunado para português\n",
    "   Modelo: lipaoMai/bert-sentiment-model-portuguese\n",
    "\n",
    "2. sentimento_score\n",
    "   Confiança do modelo na classificação do sentimento\n",
    "   Valores: 0.0 a 1.0 (0% a 100%)\n",
    "   Exemplo: 0.65 = 65% de confiança\n",
    "   \n",
    "   Interpretação:\n",
    "   - 0.0-0.5: Baixa confiança\n",
    "   - 0.5-0.7: Confiança média\n",
    "   - 0.7-1.0: Alta confiança\n",
    "\n",
    "3. complexidade_sentenca\n",
    "   Nível de complexidade/dificuldade de leitura do texto\n",
    "   Valores possíveis:\n",
    "   - alta: Texto muito técnico/complexo (70.5% dos casos)\n",
    "   - média: Complexidade padrão jurídica (29.4% dos casos)\n",
    "   - baixa: Texto relativamente simples (0.1% dos casos)\n",
    "   \n",
    "   Método: Índice Flesch Reading Ease adaptado para português\n",
    "   Referência acadêmica: Flesch, R. (1948)\n",
    "\n",
    "4. complexidade_score\n",
    "   Score numérico do Índice Flesch Reading Ease\n",
    "   Valores: 0 a 100 (quanto MAIOR, mais FÁCIL de ler)\n",
    "   \n",
    "   Interpretação:\n",
    "   - 0-30: Muito difícil (nível universitário/técnico)\n",
    "   - 30-50: Difícil (nível superior)\n",
    "   - 50-60: Moderadamente difícil\n",
    "   - 60-70: Razoável\n",
    "   - 70-100: Fácil\n",
    "   \n",
    "   Média dos textos jurídicos: ~22.8 (muito difícil)\n",
    "   \n",
    "   Classificação automática:\n",
    "   - alta complexidade: score 0-35\n",
    "   - média complexidade: score 36-55\n",
    "   - baixa complexidade: score 56-100\n",
    "\n",
    "METODOLOGIA:\n",
    "-----------\n",
    "Sentimento: Modelo de aprendizado profundo (BERT) treinado em textos portugueses\n",
    "Complexidade: Métrica linguística consolidada (Flesch Reading Ease)\n",
    "\n",
    "OBSERVAÇÕES:\n",
    "-----------\n",
    "- Textos jurídicos são naturalmente formais (maioria \"neutro\")\n",
    "- Textos jurídicos são naturalmente complexos (maioria \"alta\")\n",
    "- Scores de confiança < 0.6 devem ser interpretados com cautela\n",
    "- Análise determinística: mesmo texto = mesmo resultado\n",
    "\"\"\"\n",
    "\n",
    "with open('LEGENDA_NLP.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(legenda)\n",
    "\n",
    "print(\"Legenda salva: LEGENDA_NLP.txt\\n\")\n",
    "\n",
    "# ==================== SALVAR ARQUIVOS ====================\n",
    "print(\"5. Salvando arquivos finais...\\n\")\n",
    "\n",
    "# CSV com encoding UTF-8-SIG (compatível com Excel)\n",
    "df_analise.to_csv('processos_tjac_completo_nlp.csv', \n",
    "                  index=False, \n",
    "                  encoding='utf-8-sig')\n",
    "print(\"Salvo: processos_tjac_completo_nlp.csv\")\n",
    "\n",
    "# CSV com separador ponto-e-vírgula (Excel brasileiro)\n",
    "df_analise.to_csv('processos_tjac_completo_nlp_excel.csv', \n",
    "                  index=False, \n",
    "                  encoding='utf-8-sig',\n",
    "                  sep=';')\n",
    "print(\"Salvo: processos_tjac_completo_nlp_excel.csv (sep=;)\")\n",
    "\n",
    "# Excel nativo\n",
    "df_analise.to_excel('processos_tjac_completo_nlp.xlsx', \n",
    "                    index=False, \n",
    "                    engine='openpyxl')\n",
    "print(\"Salvo: processos_tjac_completo_nlp.xlsx\")\n",
    "\n",
    "# ==================== RESUMO ====================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ARQUIVOS GERADOS COM SUCESSO!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal de processos: {len(df_analise)}\")\n",
    "print(f\"Total de colunas: {len(df_analise.columns)}\")\n",
    "print()\n",
    "print(\"Arquivos gerados:\")\n",
    "print(\"  1. processos_tjac_completo_nlp.csv (padrão)\")\n",
    "print(\"  2. processos_tjac_completo_nlp_excel.csv (Excel BR)\")\n",
    "print(\"  3. processos_tjac_completo_nlp.xlsx (Excel nativo)\")\n",
    "print(\"  4. LEGENDA_NLP.txt (documentação)\")\n",
    "print()\n",
    "print(\"Novas colunas NLP:\")\n",
    "print(\"  • sentimento_sentenca (positivo/neutro/negativo)\")\n",
    "print(\"  • sentimento_score (0-1)\")\n",
    "print(\"  • complexidade_sentenca (alta/média/baixa)\")\n",
    "print(\"  • complexidade_score (0-100)\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
